{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras import layers, models, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import urllib.request\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_dir(dir_path):\n",
    "    imgs = []\n",
    "    y = []\n",
    "    for file in os.listdir(dir_path):\n",
    "        path = dir_path + file\n",
    "        img = cv2.imread(path)\n",
    "        imgs.append(img)\n",
    "    imgs = np.array(imgs)/255\n",
    "    y = [0 if 'REAL' in dir_path else 1 for i in range(len(imgs))]\n",
    "    return imgs, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(file):\n",
    "    img = cv2.imread(file)\n",
    "    img = cv2.resize(img, (32, 32))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_real_path = '../data/train/REAL/'\n",
    "train_fake_path = '../data/train/FAKE/'\n",
    "test_real_path = '../data/test/REAL/'\n",
    "test_fake_path = '../data/test/FAKE/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_real_imgs, train_real_y = get_df_from_dir(train_real_path)\n",
    "train_fake_imgs, train_fake_y = get_df_from_dir(train_fake_path)\n",
    "test_real_imgs, test_real_y = get_df_from_dir(test_real_path)\n",
    "test_fake_imgs, test_fake_y = get_df_from_dir(test_fake_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((train_real_imgs, train_fake_imgs))\n",
    "y = np.concatenate((train_real_y, train_fake_y))\n",
    "X_test = np.concatenate((test_real_imgs, test_fake_imgs))\n",
    "y_test = np.concatenate((test_real_y, test_fake_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 32, 32, 3), (100000,), (20000, 32, 32, 3), (20000,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_cnn_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Rescaling(1./255, input_shape=(32, 32, 3)))\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = initialize_cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(learning_rate=1e-4):\n",
    "    model = initialize_cnn_model()\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, name):\n",
    "    model.save(f\"../model/{name}\" + '.h5')\n",
    "\n",
    "def load_model(name):\n",
    "    return models.load_model(f\"../model/{name}\" + '.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_val,\n",
    "        y_val,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        patience=5\n",
    "        ):\n",
    "    es = keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience)\n",
    "    model = compile_model()\n",
    "    history = model.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        epochs=epochs, \n",
    "        batch_size=batch_size, \n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[es]\n",
    "        )\n",
    "    accuracy = round(history.history['accuracy'][-1], 2)\n",
    "    date = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    save_model(model, f\"model_{accuracy}_{date}\")\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      " 566/2500 [=====>........................] - ETA: 24s - loss: 0.7200 - accuracy: 0.5515"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/aminebenani/code/aixhunter/notebooks/mythunder11_data_exploration.ipynb Cell 17\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/aminebenani/code/aixhunter/notebooks/mythunder11_data_exploration.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model, history \u001b[39m=\u001b[39m train_model(X_train, y_train, X_val, y_val, epochs\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, patience\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
      "\u001b[1;32m/Users/aminebenani/code/aixhunter/notebooks/mythunder11_data_exploration.ipynb Cell 17\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aminebenani/code/aixhunter/notebooks/mythunder11_data_exploration.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m es \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mEarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39mpatience)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aminebenani/code/aixhunter/notebooks/mythunder11_data_exploration.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m model \u001b[39m=\u001b[39m compile_model()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/aminebenani/code/aixhunter/notebooks/mythunder11_data_exploration.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aminebenani/code/aixhunter/notebooks/mythunder11_data_exploration.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     X_train, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aminebenani/code/aixhunter/notebooks/mythunder11_data_exploration.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     y_train, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aminebenani/code/aixhunter/notebooks/mythunder11_data_exploration.ipynb#X16sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aminebenani/code/aixhunter/notebooks/mythunder11_data_exploration.ipynb#X16sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aminebenani/code/aixhunter/notebooks/mythunder11_data_exploration.ipynb#X16sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(X_val, y_val),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aminebenani/code/aixhunter/notebooks/mythunder11_data_exploration.ipynb#X16sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[es]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aminebenani/code/aixhunter/notebooks/mythunder11_data_exploration.ipynb#X16sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aminebenani/code/aixhunter/notebooks/mythunder11_data_exploration.ipynb#X16sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m accuracy \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aminebenani/code/aixhunter/notebooks/mythunder11_data_exploration.ipynb#X16sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m date \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\u001b[39m.\u001b[39mstrftime(\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mH\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM\u001b[39m\u001b[39m%\u001b[39m\u001b[39mS\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, history = train_model(X_train, y_train, X_val, y_val, epochs=1000, batch_size=32, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model_0.9490749835968018_20230605-152407')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/aminebenani/code/aixhunter/notebooks/mythunder11_data_exploration.ipynb Cell 19\u001b[0m in \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aminebenani/code/aixhunter/notebooks/mythunder11_data_exploration.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     plt\u001b[39m.\u001b[39mlegend(loc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlower right\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aminebenani/code/aixhunter/notebooks/mythunder11_data_exploration.ipynb#X20sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/aminebenani/code/aixhunter/notebooks/mythunder11_data_exploration.ipynb#X20sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m plot_history(history)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_history(history):\n",
    "    plt.plot(history.history['accuracy'], label='accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/aminebenani/code/aixhunter/notebooks/mythunder11_data_exploration.ipynb Cell 20\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/aminebenani/code/aixhunter/notebooks/mythunder11_data_exploration.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_accuracy \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aminebenani/code/aixhunter/notebooks/mythunder11_data_exploration.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_accuracy\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "train_accuracy = history.history['accuracy'][-1]\n",
    "train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 2s 4ms/step - loss: 0.1573 - accuracy: 0.9508\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = model.evaluate(X_test, y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.01325815]], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_test_1 = np.expand_dims(X_test[6000], axis=0)\n",
    "y_pred = model.predict(X_test_1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5946 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5945842266082764, 1.0]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9508000016212463"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_VGG16():\n",
    "    model = keras.applications.VGG16(\n",
    "        weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "        input_shape=(32, 32, 3),\n",
    "        include_top=False\n",
    "        )  # Do not include the ImageNet classifier at the top.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_nontrainable_layers(model):\n",
    "    model.trainable = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_last_layers(model):\n",
    "    '''Take a pre-trained model, set its parameters as non-trainable, and add additional trainable layers on top'''\n",
    "    rescale_layer = layers.Rescaling(1./255, input_shape=(32, 32, 3))\n",
    "    base_model = set_nontrainable_layers(model)\n",
    "    flatten_layer = layers.Flatten()\n",
    "    dense_layer = layers.Dense(500, activation='relu')\n",
    "    prediction_layer = layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "    \n",
    "    model = models.Sequential([\n",
    "        \n",
    "        base_model,\n",
    "        flatten_layer,\n",
    "        dense_layer,\n",
    "        prediction_layer\n",
    "    ])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rescale_layer():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = load_model_VGG16()\n",
    "    model = add_last_layers(model)\n",
    "\n",
    "    adam = optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=adam,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', 'Precision', 'Recall']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_val,\n",
    "        y_val,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        patience=5\n",
    "        ):\n",
    "    es = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=patience,\n",
    "        restore_best_weights=True,\n",
    "        )\n",
    "    model = build_model()\n",
    "    history = model.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        epochs=epochs, \n",
    "        batch_size=batch_size, \n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[es]\n",
    "        )\n",
    "    accuracy = round(history.history['accuracy'][-1], 2)\n",
    "    date = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    save_model(model, f\"model_{accuracy}_{date}\")\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 11:36:23.295354: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 164s 65ms/step - loss: 0.4045 - accuracy: 0.8177 - precision: 0.8183 - recall: 0.8173 - val_loss: 0.3556 - val_accuracy: 0.8457 - val_precision: 0.8432 - val_recall: 0.8472\n",
      "Epoch 2/1000\n",
      "2080/2500 [=======================>......] - ETA: 22s - loss: 0.3446 - accuracy: 0.8495 - precision: 0.8503 - recall: 0.8498"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_model(X_train, y_train, X_val, y_val, epochs\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, patience\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[21], line 16\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(X_train, y_train, X_val, y_val, epochs, batch_size, patience)\u001b[0m\n\u001b[1;32m     10\u001b[0m es \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mEarlyStopping(\n\u001b[1;32m     11\u001b[0m     monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m     patience\u001b[39m=\u001b[39mpatience,\n\u001b[1;32m     13\u001b[0m     restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     14\u001b[0m     )\n\u001b[1;32m     15\u001b[0m model \u001b[39m=\u001b[39m build_model()\n\u001b[0;32m---> 16\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     17\u001b[0m     X_train, \n\u001b[1;32m     18\u001b[0m     y_train, \n\u001b[1;32m     19\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs, \n\u001b[1;32m     20\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size, \n\u001b[1;32m     21\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(X_val, y_val),\n\u001b[1;32m     22\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[es]\n\u001b[1;32m     23\u001b[0m     )\n\u001b[1;32m     24\u001b[0m accuracy \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], \u001b[39m2\u001b[39m)\n\u001b[1;32m     25\u001b[0m date \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\u001b[39m.\u001b[39mstrftime(\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mH\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM\u001b[39m\u001b[39m%\u001b[39m\u001b[39mS\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/aixhunter/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/aixhunter/lib/python3.10/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/aixhunter/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/aixhunter/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/aixhunter/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/aixhunter/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/aixhunter/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/aixhunter/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/aixhunter/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, history = train_model(X_train, y_train, X_val, y_val, epochs=1000, batch_size=32, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_prediction = model.predict(X_test)\n",
    "\n",
    "#Create confusion matrix and normalizes it over predicted (columns)\n",
    "result = confusion_matrix(y_test, y_prediction , normalize='pred')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on real images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2d03ee050>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'https://upload.wikimedia.org/wikipedia/commons/1/15/Cat_August_2010-4.jpg'\n",
    "res = urllib.request.urlopen(url)\n",
    "img = cv2.imdecode(np.asarray(bytearray(res.read())), 1)\n",
    "img = cv2.resize(img, (32, 32))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_img(url, model):\n",
    "    res = urllib.request.urlopen(url)\n",
    "    img = cv2.imdecode(np.asarray(bytearray(res.read()), dtype=np.uint8), 1)\n",
    "    img = cv2.resize(img, (32, 32))\n",
    "    img = img/255.\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    print(img.shape)\n",
    "    return model.predict(img)\n",
    "\n",
    "\n",
    "def test_img_local(path, model):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, (32, 32))\n",
    "    img = img/255.\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    print(img.shape)\n",
    "    return model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 32, 3)\n",
      "1/1 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.97634786]], dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img_local('/Users/aminebenani/Downloads/IMG_0267_crop.png', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
